{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import numpy as np\n",
    "from numpy import NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#脏数据 空值、异常值、重复值  \n",
    "#手段1: 删除 dropna()\n",
    "#手段2:  修正  \n",
    "#手段3： 删除重复值 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2\n",
      "0  1.0  2.0  3.0\n",
      "1  NaN  NaN  2.0\n",
      "2  NaN  NaN  NaN\n",
      "3  8.0  8.0  NaN\n",
      "     0    1    2\n",
      "0  1.0  2.0  3.0\n",
      "1  NaN  NaN  2.0\n",
      "3  8.0  8.0  NaN\n"
     ]
    }
   ],
   "source": [
    "# 2 处理DataFrame对象\n",
    "df1=pd.DataFrame([[1,2,3],[NaN,NaN,2],[NaN,NaN,NaN],[8,8,NaN]])\n",
    "print(df1)\n",
    "\n",
    "# 默认滤除所有包含NaN：\n",
    "# print(df1.dropna())\n",
    "\n",
    "# 传入how=‘all’滤除全为NaN的行：\n",
    "# print(df1.dropna(how='all')) # 默认情况下是how='any'，只要有nan就删除\n",
    "\n",
    "# 传入axis=1滤除列：\n",
    "# print(df1.dropna(axis=1,how=\"all\"))\n",
    "\n",
    "#传入thresh=n保留至少有n个非NaN数据的行：\n",
    "# print(df1.dropna(thresh=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2    3    4\n",
      "0  9  0  2  9.0  8.0\n",
      "1  4  1  6  NaN  8.0\n",
      "2  0  5  3  NaN  NaN\n",
      "3  4  2  4  NaN  NaN\n",
      "4  3  5  3  4.0  9.0\n",
      "   0  1  2    3    4\n",
      "0  9  0  2  9.0  8.0\n",
      "1  4  1  6  9.0  8.0\n",
      "2  0  5  3  9.0  8.0\n",
      "3  4  2  4  9.0  8.0\n",
      "4  3  5  3  4.0  9.0\n",
      "   0  1  2    3    4\n",
      "0  9  0  2  9.0  8.0\n",
      "1  4  1  6  NaN  8.0\n",
      "2  0  5  3  NaN  NaN\n",
      "3  4  2  4  4.0  9.0\n",
      "4  3  5  3  4.0  9.0\n",
      "     0    1    2    3    4\n",
      "0  9.0  0.0  2.0  9.0  8.0\n",
      "1  4.0  1.0  6.0  6.0  8.0\n",
      "2  0.0  5.0  3.0  3.0  NaN\n",
      "3  4.0  2.0  4.0  4.0  NaN\n",
      "4  3.0  5.0  3.0  4.0  9.0\n"
     ]
    }
   ],
   "source": [
    "# 3 填充缺失数据\n",
    "df1=pd.DataFrame([[1,2,3],[NaN,NaN,2],[NaN,NaN,NaN],[8,8,NaN]])\n",
    "print(df1)\n",
    "\n",
    "# 用常数填充fillna\n",
    "print(df1.fillna(0))\n",
    "# print(df1)\n",
    "#传入inplace=True直接修改原对象：\n",
    "df1.fillna(0,inplace=True)\n",
    "print(df1)\n",
    "\n",
    "# 通过字典填充不同的常数\n",
    "#{key 列号: value 数值 }\n",
    "print(df1.fillna({0:10,1:20,2:30})) \n",
    "\n",
    "# 填充平均值\n",
    "print(df1.fillna(df1.mean()))\n",
    "# # 如果只填充一列\n",
    "# print(df1.iloc[:,1].fillna(5,inplace = True))\n",
    "# print(df1)\n",
    "\n",
    "# 传入method=” “改变插值方式：\n",
    "df2=pd.DataFrame(np.random.randint(0,10,(5,5)))\n",
    "df2.iloc[1:4,3]=NaN\n",
    "df2.iloc[2:4,4]=NaN\n",
    "print(df2)\n",
    "# 用前面的值来填充ffill   用后面的值来填充bfill\n",
    "print(df2.fillna(method='ffill'))\n",
    "\n",
    "# # 传入limit=” “限制填充行数：\n",
    "print(df2.fillna(method='bfill',limit=1))\n",
    "\n",
    "# # 传入axis=” “修改填充方向：\n",
    "print(df2.fillna(method=\"ffill\",limit=1,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4.0\n",
      "1    NaN\n",
      "2    8.0\n",
      "3    NaN\n",
      "4    5.0\n",
      "dtype: float64\n",
      "0    4.0\n",
      "2    8.0\n",
      "4    5.0\n",
      "dtype: float64\n",
      "*****\n",
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "dtype: bool\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4    False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    4.0\n",
       "2    8.0\n",
       "4    5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import nan as NaN\n",
    "# 1通过**dropna()**滤除缺失数据：\n",
    "se=pd.Series([4,NaN,8,NaN,5])\n",
    "print(se)\n",
    "print(se.dropna()) #删除异常值 \n",
    "print(\"*****\")\n",
    "print(se.notnull()) \n",
    "print(se.isnull())  \n",
    "\n",
    "# #通过布尔序列 过滤 \n",
    "se[se.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  a\n",
      "1  1  a\n",
      "2  1  b\n",
      "3  2  b\n",
      "4  2  b\n",
      "5  3  c\n",
      "6  1  a\n",
      "   A  B\n",
      "0  1  a\n",
      "2  1  b\n",
      "3  2  b\n",
      "5  3  c\n"
     ]
    }
   ],
   "source": [
    "# 4 移除重复数据\n",
    "'''\n",
    "DataFrame中经常会出现重复行，利用duplicated()函数返回每一行判断是否重复的结果（重复则为True)\n",
    "'''\n",
    "df1=pd.DataFrame({'A':[1,1,1,2,2,3,1],'B':list(\"aabbbca\")})\n",
    "print(df1)\n",
    "\n",
    "# 判断每一行是否重复(结果是bool值，TRUE代表重复的)\n",
    "print(df1.duplicated())\n",
    "\n",
    "# 去除全部的重复行\n",
    "print(df1.drop_duplicates())\n",
    "\n",
    "# # 指定列去除重复行\n",
    "# print(df1.drop_duplicates(['A']))\n",
    "\n",
    "# 保留重复行中的最后一行\n",
    "print(df1.drop_duplicates(['A'],keep='last'))\n",
    "\n",
    "# 去除重复的同时改变DataFrame对象\n",
    "# df1.drop_duplicates(['A','B'],inplace=True)\n",
    "# print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Red  Green\n",
      "a    1      5\n",
      "b    3      0\n",
      "c    5      3\n",
      "   Blue  Yellow\n",
      "c     1       6\n",
      "d     9       6\n",
      "e     8       7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Red</th>\n",
       "      <th>Green</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Yellow</th>\n",
       "      <th>Brown</th>\n",
       "      <th>Pink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Red  Green  Blue  Yellow  Brown  Pink\n",
       "a  1.0    5.0   NaN     NaN    3.0   1.0\n",
       "b  3.0    0.0   NaN     NaN    NaN   NaN\n",
       "c  5.0    3.0   1.0     6.0    NaN   NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用join合并，着重关注的是行的合并\n",
    "import pandas as pd\n",
    "df3=pd.DataFrame({'Red':[1,3,5],'Green':[5,0,3]},index=list('abc'))\n",
    "df4=pd.DataFrame({'Blue':[1,9,8],'Yellow':[6,6,7]},index=list('cde'))\n",
    "print(df3)\n",
    "print(df4)\n",
    "\n",
    "# # 简单合并（默认是left左连接,以左侧df3为基础）\n",
    "df3.join(df4,how='left')\n",
    "\n",
    "# # 右链接\n",
    "df3.join(df4,how='right')\n",
    "\n",
    "# # 外链接。也称全连接\n",
    "df3.join(df4,how='outer')\n",
    "\n",
    "# # 合并多个DataFrame对象\n",
    "df5=pd.DataFrame({'Brown':[3,4,5],'Pink':[1,1,2]},index=list('aed'))\n",
    "df3.join([df4,df5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学院老师 名字 性别   职称\n",
      "编号             \n",
      "1001  A  男  副教授\n",
      "1002  B  女   讲师\n",
      "1003  C  男   助教\n",
      "1004  D  男   教授\n",
      "1005  E  女   助教\n",
      "课程   名字     课程   职称\n",
      "编号                 \n",
      "1001  A    C++  副教授\n",
      "1002  B  计算机导论   讲师\n",
      "1004  D     汇编   教授\n",
      "1001  A   数据结构  副教授\n",
      "3001  X  马克思原理   讲师\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>名字</th>\n",
       "      <th>性别</th>\n",
       "      <th>职称</th>\n",
       "      <th>课程</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>男</td>\n",
       "      <td>副教授</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>男</td>\n",
       "      <td>副教授</td>\n",
       "      <td>数据结构</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>女</td>\n",
       "      <td>讲师</td>\n",
       "      <td>计算机导论</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>男</td>\n",
       "      <td>助教</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>男</td>\n",
       "      <td>教授</td>\n",
       "      <td>汇编</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E</td>\n",
       "      <td>女</td>\n",
       "      <td>助教</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>讲师</td>\n",
       "      <td>马克思原理</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  名字   性别   职称     课程\n",
       "0  A    男  副教授    C++\n",
       "1  A    男  副教授   数据结构\n",
       "2  B    女   讲师  计算机导论\n",
       "3  C    男   助教    NaN\n",
       "4  D    男   教授     汇编\n",
       "5  E    女   助教    NaN\n",
       "6  X  NaN   讲师  马克思原理"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用merge，着重关注的是列的合并\n",
    "df1=pd.DataFrame({'名字':list('ABCDE'),'性别':['男','女','男','男','女'],'职称':['副教授','讲师','助教','教授','助教']},index=range(1001,1006))\n",
    "df1.columns.name='学院老师'\n",
    "df1.index.name='编号'\n",
    "print(df1)\n",
    "\n",
    "df2=pd.DataFrame({'名字':list('ABDAX'),'课程':['C++','计算机导论','汇编','数据结构','马克思原理'],'职称':['副教授','讲师','教授','副教授','讲师']},index=[1001,1002,1004,1001,3001])\n",
    "df2.columns.name='课程'\n",
    "df2.index.name='编号'\n",
    "print(df2)\n",
    "\n",
    "# # 默认下是根据左右对象中出现同名的列作为连接的键，且连接方式是how=’inner’\n",
    "# print(pd.merge(df1,df2))# 返回匹配的\n",
    "\n",
    "# # 指定列名合并\n",
    "# pd.merge(df1,df2,on='名字',suffixes=['_1','_2'])# 返回匹配的\n",
    "\n",
    "# # 连接方式，根据左侧为准\n",
    "# pd.merge(df1,df2,how='left')\n",
    "\n",
    "# # 根据右侧为准\n",
    "# pd.merge(df1,df2,how='right')\n",
    "\n",
    "# # 所有\n",
    "pd.merge(df1,df2,how='outer')\n",
    "\n",
    "# # 根据多个键进行连接\n",
    "# pd.merge(df1,df2,on=['职称','名字'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "dtype: int64\n",
      "a    3\n",
      "b    4\n",
      "c    5\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a    1\n",
       "b    2\n",
       "a    3\n",
       "b    4\n",
       "c    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 轴向连接-Concat\n",
    "# 1. Series对象的连接\n",
    "s1=pd.Series([1,2],index=list('ab'))\n",
    "s2=pd.Series([3,4,5],index=list('abc'))\n",
    "print(s1)\n",
    "print(s2)\n",
    "pd.concat([s1,s2])\n",
    "\n",
    "#横向连接 默认join = 'outer'\n",
    "# pd.concat([s1,s2],axis=1)\n",
    "\n",
    "# # 用内连接求交集(连接方式，共有’inner’,’outer’)\n",
    "# pd.concat([s1,s2],axis=1,join='inner')\n",
    "\n",
    "# # 指定部分索引进行连接  已经废弃 \n",
    "# # pd.concat([s1,s2],axis=1,join_axes=[list('abc')])\n",
    "\n",
    "# # 创建层次化索引\n",
    "# pd.concat([s1,s2],keys=['A','B'])\n",
    "\n",
    "# #当纵向连接时keys为列名\n",
    "# pd.concat([s1,s2],keys=['A','D'],axis=1)\n",
    "\n",
    "# print(\"*******\")\n",
    "# # 2. DataFrame对象的连接\n",
    "# df3=pd.DataFrame({'Red':[1,3,5],'Green':[5,0,3]},index=list('abd'))\n",
    "# df4=pd.DataFrame({'Blue':[1,9],'Yellow':[6,6]},index=list('ce'))\n",
    "# print(df3)\n",
    "# print(df4)\n",
    "# print(pd.concat([df3,df4]))\n",
    "# pd.concat([df3,df4],axis=1,keys=['A','B'])\n",
    "\n",
    "# # 用字典的方式连接同样可以创建层次化列索引\n",
    "# # {key 索引:value 数组本身}\n",
    "# pd.concat({'A':df3,'B':df4},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     97\n",
      "b    113\n",
      "c    133\n",
      "d     50\n",
      "e    126\n",
      "f     42\n",
      "dtype: int32\n",
      "a  期中    120\n",
      "   期末     74\n",
      "b  期中     61\n",
      "   期末    122\n",
      "c  期中    148\n",
      "   期末     73\n",
      "dtype: int32\n",
      "            zs   ls   ww   zl\n",
      "python 期中  126  105   94  149\n",
      "       期末   85  107   68   93\n",
      "math   期中  102  110    2   75\n",
      "       期末    0   72  144   38\n",
      "En     期中  106  128   26   41\n",
      "       期末  100  121  137   27\n"
     ]
    }
   ],
   "source": [
    "# Series也可以创建多层索引\n",
    "#index=[[第一层][第二层]]\n",
    "s = Series(np.random.randint(0,150,size=6),index=list('abcdef'))\n",
    "print(s)\n",
    "s = Series(np.random.randint(0,150,size=6),\n",
    "           index=[['a','a','b','b','c','c'],['期中','期末','期中','期末','期中','期末']])\n",
    "print(s)\n",
    "\n",
    "# DataFrame创建多层索引\n",
    "df1 = DataFrame(np.random.randint(0,150,size=(6,4)),\n",
    "               columns = ['zs','ls','ww','zl'],\n",
    "               index = [['python','python','math','math','En','En'],['期中','期末','期中','期末','期中','期末']])\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0    1    2    3\n",
      "python 期中  145    2   42   81\n",
      "       期末    1  116   25   35\n",
      "math   期中   68    3   19   67\n",
      "       期末   11    4   67   55\n",
      "En     期中    4  121  126    8\n",
      "       期末   84   95   51  104\n",
      "             0    1    2   3\n",
      "期中 python   90    2   60  18\n",
      "   math    102   93   95  69\n",
      "   En       71   38  121   1\n",
      "期末 python   53  140   53  68\n",
      "   math    113  106    5   9\n",
      "   En       87   93   86  16\n"
     ]
    }
   ],
   "source": [
    "class1=['python','python','math','math','En','En']\n",
    "class2=['期中','期末','期中','期末','期中','期末']\n",
    "m_index2=pd.MultiIndex.from_arrays([class1,class2])\n",
    "df2=DataFrame(np.random.randint(0,150,(6,4)),index=m_index2)\n",
    "print(df2)\n",
    "\n",
    "class1=['期中','期中','期中','期末','期末','期末']\n",
    "class2=['python','math','En','python','math','En']\n",
    "m_index2=pd.MultiIndex.from_arrays([class1,class2])\n",
    "df2=DataFrame(np.random.randint(0,150,(6,4)),index=m_index2)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0    1    2    3\n",
      "python 期中   47  107  102   49\n",
      "       期末   79    1  132    7\n",
      "math   期中   79  101    9  125\n",
      "       期末   93  118   60   23\n",
      "En     期中  105   61   22  120\n",
      "       期末  110  146   63  119\n"
     ]
    }
   ],
   "source": [
    "# 3. product构造 class1.size(3) * class2.size(2) = row(6)\n",
    "class1=['python','math','En']\n",
    "class2=['期中','期末']\n",
    "m_index2=pd.MultiIndex.from_product([class1,class2])\n",
    "df2=DataFrame(np.random.randint(0,150,(6,4)),index=m_index2)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a  期中     32\n",
      "   期末      3\n",
      "b  期中     24\n",
      "   期末    111\n",
      "c  期中     84\n",
      "   期末     54\n",
      "dtype: int32\n",
      "期中    32\n",
      "期末     3\n",
      "dtype: int32\n",
      "a  期中     32\n",
      "   期末      3\n",
      "b  期中     24\n",
      "   期末    111\n",
      "dtype: int32\n",
      "3\n",
      "*****\n",
      "3\n",
      "a  期末      3\n",
      "b  期中     24\n",
      "   期末    111\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "#多层索引对象的索引操作\n",
    "# series\n",
    "s = Series(np.random.randint(0,150,size=6),\n",
    "           index=[['a','a','b','b','c','c'],['期中','期末','期中','期末','期中','期末']])\n",
    "print(s)\n",
    "# 取一个第一级索引\n",
    "# print(s['a'])\n",
    "\n",
    "# 取多个第一级索引\n",
    "# print(s[['a','b']])\n",
    "\n",
    "# 根据索引获取值\n",
    "# print(s['a','期末'])\n",
    "\n",
    "# loc方法取值\n",
    "print(s.loc['a'])\n",
    "print(s.loc[['a','b']])\n",
    "print(s.loc['a','期末'])\n",
    "\n",
    "print(\"*****\")\n",
    "# iloc方法取值(iloc计算的事最内层索引)\n",
    "print(s.iloc[1])\n",
    "\n",
    "print(s.iloc[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0    1    2    3\n",
      "python 期中  105  103   36  147\n",
      "       期末   45   65  110   10\n",
      "math   期中  109   62   15  106\n",
      "       期末   35   92   69  134\n",
      "En     期中  122  117   58   72\n",
      "       期末   53  141  112   53\n",
      "python  期中    105\n",
      "        期末     45\n",
      "math    期中    109\n",
      "        期末     35\n",
      "En      期中    122\n",
      "        期末     53\n",
      "Name: 0, dtype: int32\n",
      "      0    1    2    3\n",
      "期中  105  103   36  147\n",
      "期末   45   65  110   10\n",
      "             0    1    2    3\n",
      "python 期中  105  103   36  147\n",
      "       期末   45   65  110   10\n",
      "math   期中  109   62   15  106\n",
      "       期末   35   92   69  134\n",
      "0     45\n",
      "1     65\n",
      "2    110\n",
      "3     10\n",
      "Name: (python, 期末), dtype: int32\n",
      "45\n",
      "0    105\n",
      "1    103\n",
      "2     36\n",
      "3    147\n",
      "Name: (python, 期中), dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# dataframe\n",
    "class1=['python','math','En']\n",
    "class2=['期中','期末']\n",
    "m_index2=pd.MultiIndex.from_product([class1,class2])\n",
    "df2=DataFrame(np.random.randint(0,150,(6,4)),index=m_index2)\n",
    "print(df2)\n",
    "\n",
    "# 获取列\n",
    "print(df2[0])\n",
    "\n",
    "# 一级索引\n",
    "print(df2.loc['python'])\n",
    "\n",
    "# 多个一级索引\n",
    "print(df2.loc[['python','math']])\n",
    "\n",
    "# 取一行\n",
    "print(df2.loc['python','期末'])\n",
    "\n",
    "# 取一值\n",
    "print(df2.loc['python','期末'][0])\n",
    "\n",
    "# iloc是只取最内层的索引的\n",
    "print(df2.iloc[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-05-01', '2019-05-11', '2019-05-21', '2019-05-31',\n",
      "               '2019-06-10', '2019-06-20', '2019-06-30', '2019-07-10',\n",
      "               '2019-07-20', '2019-07-30'],\n",
      "              dtype='datetime64[ns]', freq='10D')\n"
     ]
    }
   ],
   "source": [
    "# start开始，end结束时间\n",
    "# date = pd.date_range(start='20190501',end='20190530')\n",
    "# print(date)\n",
    "\n",
    "# freq：日期偏移量，取值为string, 默认为'D'，  freq='1h30min'  freq='10D'\n",
    "# periods：固定时期，取值为整数或None.这里表示取十个数\n",
    "date = pd.date_range(start='20190501',periods=10,freq='10D')\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-09', '2019-01-10', '2019-01-11', '2019-01-12',\n",
      "               '2019-01-13'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "# closed='left'表示左闭右开\n",
    "# closed = 'right'表示左开右闭\n",
    "data_time =pd.date_range(start='2019-01-09',end='2019-01-14',closed='left')\n",
    "print(data_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01    4\n",
      "2019-01-02    9\n",
      "2019-01-03    7\n",
      "2019-01-04    2\n",
      "2019-01-05    8\n",
      "2019-01-06    2\n",
      "2019-01-07    4\n",
      "2019-01-08    6\n",
      "2019-01-09    5\n",
      "2019-01-10    0\n",
      "Freq: D, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# 可以将时间作为索引\n",
    "index = pd.date_range(start='20190101',periods=10)\n",
    "df = pd.Series(np.random.randint(0,10,size = 10),index=index)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-08    6\n",
      "2019-01-09    5\n",
      "2019-01-10    0\n",
      "Freq: D, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# truncate这个函数将before指定日期之前的值全部过滤出去,after指定日期之前的值全部过滤出去.\n",
    "after = df.truncate(before='2019-01-8')\n",
    "print(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01   -0.664230\n",
      "2019-01-02   -0.902596\n",
      "2019-01-03   -1.364698\n",
      "2019-01-04    1.791811\n",
      "2019-01-05   -1.076365\n",
      "                ...   \n",
      "2021-09-22    1.303407\n",
      "2021-09-23   -0.786620\n",
      "2021-09-24   -1.436028\n",
      "2021-09-25   -0.361284\n",
      "2021-09-26   -0.556417\n",
      "Freq: D, Length: 1000, dtype: float64\n",
      "******\n",
      "2020-05-01    1.076409\n",
      "2020-05-02   -1.012363\n",
      "2020-05-03    0.480134\n",
      "2020-05-04   -0.924592\n",
      "2020-05-05    0.975410\n",
      "2020-05-06   -1.327608\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "long_ts = pd.Series(np.random.randn(1000),index=pd.date_range('1/1/2019',periods=1000))\n",
    "print(long_ts)\n",
    "print(\"******\")\n",
    "# 根据年份获取\n",
    "result = long_ts['2020']\n",
    "print(result)\n",
    "\n",
    "# 年份和日期获取\n",
    "result = long_ts['2020-05']\n",
    "print(result)\n",
    "\n",
    "# 使用切片\n",
    "result = long_ts['2020-05-01':'2020-05-06']\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-17 00:00:00   -0.070299\n",
      "2018-03-17 02:00:00   -1.338436\n",
      "2018-03-17 04:00:00   -0.578704\n",
      "2018-03-17 06:00:00    0.300917\n",
      "2018-03-17 08:00:00   -1.159701\n",
      "                         ...   \n",
      "2018-03-29 16:00:00    0.329894\n",
      "2018-03-29 18:00:00   -0.454036\n",
      "2018-03-29 20:00:00   -1.669797\n",
      "2018-03-29 22:00:00    0.517406\n",
      "2018-03-30 00:00:00    0.440349\n",
      "Freq: 2H, Length: 157, dtype: float64\n",
      "2018-03-17 08:00:00   -1.159701\n",
      "2018-03-17 10:00:00   -0.420634\n",
      "2018-03-17 12:00:00   -0.973783\n",
      "2018-03-17 14:00:00   -0.023174\n",
      "2018-03-17 16:00:00    0.376592\n",
      "                         ...   \n",
      "2018-03-29 08:00:00    1.101352\n",
      "2018-03-29 10:00:00   -1.557081\n",
      "2018-03-29 12:00:00    1.866544\n",
      "2018-03-29 14:00:00    0.150486\n",
      "2018-03-29 16:00:00    0.329894\n",
      "Length: 65, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 通过between_time()返回位于指定时间段的数据集\n",
    "index=pd.date_range(\"2018-03-17\",\"2018-03-30\",freq=\"2H\")\n",
    "ts = pd.Series(np.random.randn(157),index=index)\n",
    "print(ts)\n",
    "print(ts.between_time(\"7:00\",\"17:00\"))\n",
    "\n",
    "# datetime date['2020-05']  time between_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01   -1.821482\n",
      "2019-01-02   -1.236970\n",
      "2019-01-03   -1.386054\n",
      "2019-01-04    0.193786\n",
      "2019-01-05   -0.321915\n",
      "2019-01-06   -0.494599\n",
      "2019-01-07    1.441712\n",
      "2019-01-08    0.897267\n",
      "2019-01-09    0.524598\n",
      "2019-01-10    1.234626\n",
      "Freq: D, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 6. 移位日期\n",
    "ts = pd.Series(np.random.randn(10),index=pd.date_range('1/1/2019',periods=10))\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-01-03   -1.821482\n",
       "2019-01-04   -1.236970\n",
       "2019-01-05   -1.386054\n",
       "2019-01-06    0.193786\n",
       "2019-01-07   -0.321915\n",
       "2019-01-08   -0.494599\n",
       "2019-01-09    1.441712\n",
       "2019-01-10    0.897267\n",
       "2019-01-11    0.524598\n",
       "2019-01-12    1.234626\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向上移动\n",
    "ts.shift(periods=2,fill_value=100,freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-01-01         NaN\n",
       "2019-01-02         NaN\n",
       "2019-01-03         NaN\n",
       "2019-01-04         NaN\n",
       "2019-01-05         NaN\n",
       "2019-01-06   -1.821482\n",
       "2019-01-07   -1.236970\n",
       "2019-01-08   -1.386054\n",
       "2019-01-09    0.193786\n",
       "2019-01-10   -0.321915\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ts.tshift(5)\n",
    "ts.shift(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-04-11 08:19:00')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(1554970740000,unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Africa/Abidjan', 'Africa/Accra', 'Africa/Addis_Ababa', 'Africa/Algiers', 'Africa/Asmara', 'Africa/Bamako', 'Africa/Bangui', 'Africa/Banjul', 'Africa/Bissau', 'Africa/Blantyre', 'Africa/Brazzaville', 'Africa/Bujumbura', 'Africa/Cairo', 'Africa/Casablanca', 'Africa/Ceuta', 'Africa/Conakry', 'Africa/Dakar', 'Africa/Dar_es_Salaam', 'Africa/Djibouti', 'Africa/Douala', 'Africa/El_Aaiun', 'Africa/Freetown', 'Africa/Gaborone', 'Africa/Harare', 'Africa/Johannesburg', 'Africa/Juba', 'Africa/Kampala', 'Africa/Khartoum', 'Africa/Kigali', 'Africa/Kinshasa', 'Africa/Lagos', 'Africa/Libreville', 'Africa/Lome', 'Africa/Luanda', 'Africa/Lubumbashi', 'Africa/Lusaka', 'Africa/Malabo', 'Africa/Maputo', 'Africa/Maseru', 'Africa/Mbabane', 'Africa/Mogadishu', 'Africa/Monrovia', 'Africa/Nairobi', 'Africa/Ndjamena', 'Africa/Niamey', 'Africa/Nouakchott', 'Africa/Ouagadougou', 'Africa/Porto-Novo', 'Africa/Sao_Tome', 'Africa/Tripoli', 'Africa/Tunis', 'Africa/Windhoek', 'America/Adak', 'America/Anchorage', 'America/Anguilla', 'America/Antigua', 'America/Araguaina', 'America/Argentina/Buenos_Aires', 'America/Argentina/Catamarca', 'America/Argentina/Cordoba', 'America/Argentina/Jujuy', 'America/Argentina/La_Rioja', 'America/Argentina/Mendoza', 'America/Argentina/Rio_Gallegos', 'America/Argentina/Salta', 'America/Argentina/San_Juan', 'America/Argentina/San_Luis', 'America/Argentina/Tucuman', 'America/Argentina/Ushuaia', 'America/Aruba', 'America/Asuncion', 'America/Atikokan', 'America/Bahia', 'America/Bahia_Banderas', 'America/Barbados', 'America/Belem', 'America/Belize', 'America/Blanc-Sablon', 'America/Boa_Vista', 'America/Bogota', 'America/Boise', 'America/Cambridge_Bay', 'America/Campo_Grande', 'America/Cancun', 'America/Caracas', 'America/Cayenne', 'America/Cayman', 'America/Chicago', 'America/Chihuahua', 'America/Costa_Rica', 'America/Creston', 'America/Cuiaba', 'America/Curacao', 'America/Danmarkshavn', 'America/Dawson', 'America/Dawson_Creek', 'America/Denver', 'America/Detroit', 'America/Dominica', 'America/Edmonton', 'America/Eirunepe', 'America/El_Salvador', 'America/Fort_Nelson', 'America/Fortaleza', 'America/Glace_Bay', 'America/Goose_Bay', 'America/Grand_Turk', 'America/Grenada', 'America/Guadeloupe', 'America/Guatemala', 'America/Guayaquil', 'America/Guyana', 'America/Halifax', 'America/Havana', 'America/Hermosillo', 'America/Indiana/Indianapolis', 'America/Indiana/Knox', 'America/Indiana/Marengo', 'America/Indiana/Petersburg', 'America/Indiana/Tell_City', 'America/Indiana/Vevay', 'America/Indiana/Vincennes', 'America/Indiana/Winamac', 'America/Inuvik', 'America/Iqaluit', 'America/Jamaica', 'America/Juneau', 'America/Kentucky/Louisville', 'America/Kentucky/Monticello', 'America/Kralendijk', 'America/La_Paz', 'America/Lima', 'America/Los_Angeles', 'America/Lower_Princes', 'America/Maceio', 'America/Managua', 'America/Manaus', 'America/Marigot', 'America/Martinique', 'America/Matamoros', 'America/Mazatlan', 'America/Menominee', 'America/Merida', 'America/Metlakatla', 'America/Mexico_City', 'America/Miquelon', 'America/Moncton', 'America/Monterrey', 'America/Montevideo', 'America/Montserrat', 'America/Nassau', 'America/New_York', 'America/Nipigon', 'America/Nome', 'America/Noronha', 'America/North_Dakota/Beulah', 'America/North_Dakota/Center', 'America/North_Dakota/New_Salem', 'America/Nuuk', 'America/Ojinaga', 'America/Panama', 'America/Pangnirtung', 'America/Paramaribo', 'America/Phoenix', 'America/Port-au-Prince', 'America/Port_of_Spain', 'America/Porto_Velho', 'America/Puerto_Rico', 'America/Punta_Arenas', 'America/Rainy_River', 'America/Rankin_Inlet', 'America/Recife', 'America/Regina', 'America/Resolute', 'America/Rio_Branco', 'America/Santarem', 'America/Santiago', 'America/Santo_Domingo', 'America/Sao_Paulo', 'America/Scoresbysund', 'America/Sitka', 'America/St_Barthelemy', 'America/St_Johns', 'America/St_Kitts', 'America/St_Lucia', 'America/St_Thomas', 'America/St_Vincent', 'America/Swift_Current', 'America/Tegucigalpa', 'America/Thule', 'America/Thunder_Bay', 'America/Tijuana', 'America/Toronto', 'America/Tortola', 'America/Vancouver', 'America/Whitehorse', 'America/Winnipeg', 'America/Yakutat', 'America/Yellowknife', 'Antarctica/Casey', 'Antarctica/Davis', 'Antarctica/DumontDUrville', 'Antarctica/Macquarie', 'Antarctica/Mawson', 'Antarctica/McMurdo', 'Antarctica/Palmer', 'Antarctica/Rothera', 'Antarctica/Syowa', 'Antarctica/Troll', 'Antarctica/Vostok', 'Arctic/Longyearbyen', 'Asia/Aden', 'Asia/Almaty', 'Asia/Amman', 'Asia/Anadyr', 'Asia/Aqtau', 'Asia/Aqtobe', 'Asia/Ashgabat', 'Asia/Atyrau', 'Asia/Baghdad', 'Asia/Bahrain', 'Asia/Baku', 'Asia/Bangkok', 'Asia/Barnaul', 'Asia/Beirut', 'Asia/Bishkek', 'Asia/Brunei', 'Asia/Chita', 'Asia/Choibalsan', 'Asia/Colombo', 'Asia/Damascus', 'Asia/Dhaka', 'Asia/Dili', 'Asia/Dubai', 'Asia/Dushanbe', 'Asia/Famagusta', 'Asia/Gaza', 'Asia/Hebron', 'Asia/Ho_Chi_Minh', 'Asia/Hong_Kong', 'Asia/Hovd', 'Asia/Irkutsk', 'Asia/Jakarta', 'Asia/Jayapura', 'Asia/Jerusalem', 'Asia/Kabul', 'Asia/Kamchatka', 'Asia/Karachi', 'Asia/Kathmandu', 'Asia/Khandyga', 'Asia/Kolkata', 'Asia/Krasnoyarsk', 'Asia/Kuala_Lumpur', 'Asia/Kuching', 'Asia/Kuwait', 'Asia/Macau', 'Asia/Magadan', 'Asia/Makassar', 'Asia/Manila', 'Asia/Muscat', 'Asia/Nicosia', 'Asia/Novokuznetsk', 'Asia/Novosibirsk', 'Asia/Omsk', 'Asia/Oral', 'Asia/Phnom_Penh', 'Asia/Pontianak', 'Asia/Pyongyang', 'Asia/Qatar', 'Asia/Qostanay', 'Asia/Qyzylorda', 'Asia/Riyadh', 'Asia/Sakhalin', 'Asia/Samarkand', 'Asia/Seoul', 'Asia/Shanghai', 'Asia/Singapore', 'Asia/Srednekolymsk', 'Asia/Taipei', 'Asia/Tashkent', 'Asia/Tbilisi', 'Asia/Tehran', 'Asia/Thimphu', 'Asia/Tokyo', 'Asia/Tomsk', 'Asia/Ulaanbaatar', 'Asia/Urumqi', 'Asia/Ust-Nera', 'Asia/Vientiane', 'Asia/Vladivostok', 'Asia/Yakutsk', 'Asia/Yangon', 'Asia/Yekaterinburg', 'Asia/Yerevan', 'Atlantic/Azores', 'Atlantic/Bermuda', 'Atlantic/Canary', 'Atlantic/Cape_Verde', 'Atlantic/Faroe', 'Atlantic/Madeira', 'Atlantic/Reykjavik', 'Atlantic/South_Georgia', 'Atlantic/St_Helena', 'Atlantic/Stanley', 'Australia/Adelaide', 'Australia/Brisbane', 'Australia/Broken_Hill', 'Australia/Currie', 'Australia/Darwin', 'Australia/Eucla', 'Australia/Hobart', 'Australia/Lindeman', 'Australia/Lord_Howe', 'Australia/Melbourne', 'Australia/Perth', 'Australia/Sydney', 'Canada/Atlantic', 'Canada/Central', 'Canada/Eastern', 'Canada/Mountain', 'Canada/Newfoundland', 'Canada/Pacific', 'Europe/Amsterdam', 'Europe/Andorra', 'Europe/Astrakhan', 'Europe/Athens', 'Europe/Belgrade', 'Europe/Berlin', 'Europe/Bratislava', 'Europe/Brussels', 'Europe/Bucharest', 'Europe/Budapest', 'Europe/Busingen', 'Europe/Chisinau', 'Europe/Copenhagen', 'Europe/Dublin', 'Europe/Gibraltar', 'Europe/Guernsey', 'Europe/Helsinki', 'Europe/Isle_of_Man', 'Europe/Istanbul', 'Europe/Jersey', 'Europe/Kaliningrad', 'Europe/Kiev', 'Europe/Kirov', 'Europe/Lisbon', 'Europe/Ljubljana', 'Europe/London', 'Europe/Luxembourg', 'Europe/Madrid', 'Europe/Malta', 'Europe/Mariehamn', 'Europe/Minsk', 'Europe/Monaco', 'Europe/Moscow', 'Europe/Oslo', 'Europe/Paris', 'Europe/Podgorica', 'Europe/Prague', 'Europe/Riga', 'Europe/Rome', 'Europe/Samara', 'Europe/San_Marino', 'Europe/Sarajevo', 'Europe/Saratov', 'Europe/Simferopol', 'Europe/Skopje', 'Europe/Sofia', 'Europe/Stockholm', 'Europe/Tallinn', 'Europe/Tirane', 'Europe/Ulyanovsk', 'Europe/Uzhgorod', 'Europe/Vaduz', 'Europe/Vatican', 'Europe/Vienna', 'Europe/Vilnius', 'Europe/Volgograd', 'Europe/Warsaw', 'Europe/Zagreb', 'Europe/Zaporozhye', 'Europe/Zurich', 'GMT', 'Indian/Antananarivo', 'Indian/Chagos', 'Indian/Christmas', 'Indian/Cocos', 'Indian/Comoro', 'Indian/Kerguelen', 'Indian/Mahe', 'Indian/Maldives', 'Indian/Mauritius', 'Indian/Mayotte', 'Indian/Reunion', 'Pacific/Apia', 'Pacific/Auckland', 'Pacific/Bougainville', 'Pacific/Chatham', 'Pacific/Chuuk', 'Pacific/Easter', 'Pacific/Efate', 'Pacific/Enderbury', 'Pacific/Fakaofo', 'Pacific/Fiji', 'Pacific/Funafuti', 'Pacific/Galapagos', 'Pacific/Gambier', 'Pacific/Guadalcanal', 'Pacific/Guam', 'Pacific/Honolulu', 'Pacific/Kiritimati', 'Pacific/Kosrae', 'Pacific/Kwajalein', 'Pacific/Majuro', 'Pacific/Marquesas', 'Pacific/Midway', 'Pacific/Nauru', 'Pacific/Niue', 'Pacific/Norfolk', 'Pacific/Noumea', 'Pacific/Pago_Pago', 'Pacific/Palau', 'Pacific/Pitcairn', 'Pacific/Pohnpei', 'Pacific/Port_Moresby', 'Pacific/Rarotonga', 'Pacific/Saipan', 'Pacific/Tahiti', 'Pacific/Tarawa', 'Pacific/Tongatapu', 'Pacific/Wake', 'Pacific/Wallis', 'US/Alaska', 'US/Arizona', 'US/Central', 'US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']\n"
     ]
    }
   ],
   "source": [
    "import pytz  #时区 360 /24  15度， 116  15*8 = 120 \n",
    "print(pytz.common_timezones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-04-11 16:19:00+0800', tz='Asia/Shanghai')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(1554970740000,unit='ms').tz_localize('UTC').tz_convert('Asia/Shanghai')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-10-10 00:00:00')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理中文\n",
    "pd.to_datetime('2019年10月10日',format='%Y年%m月%d日')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name  Year   Salary   Bonus\n",
      "0   BOSS  2016   999999  100000\n",
      "1  Lilei  2016    20000   20000\n",
      "2  Lilei  2016    25000   20000\n",
      "3    Han  2016     3000    5000\n",
      "4   BOSS  2017  9999999  200000\n",
      "5   BOSS  2017   999999  300000\n",
      "6    Han  2017     3500    3000\n",
      "7   BOSS  2017   999999  400000\n"
     ]
    }
   ],
   "source": [
    "# 分组\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame({\n",
    "    'name':['BOSS','Lilei','Lilei','Han','BOSS','BOSS','Han','BOSS'],\n",
    "    'Year':[2016,2016,2016,2016,2017,2017,2017,2017],\n",
    "    'Salary':[999999,20000,25000,3000,9999999,999999,3500,999999],\n",
    "    'Bonus':[100000,20000,20000,5000,200000,300000,3000,400000]\n",
    "    })\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOSS\n",
      "   name  Year   Salary   Bonus\n",
      "0  BOSS  2016   999999  100000\n",
      "4  BOSS  2017  9999999  200000\n",
      "5  BOSS  2017   999999  300000\n",
      "7  BOSS  2017   999999  400000\n",
      "Han\n",
      "  name  Year  Salary  Bonus\n",
      "3  Han  2016    3000   5000\n",
      "6  Han  2017    3500   3000\n",
      "Lilei\n",
      "    name  Year  Salary  Bonus\n",
      "1  Lilei  2016   20000  20000\n",
      "2  Lilei  2016   25000  20000\n"
     ]
    }
   ],
   "source": [
    "# 根据name这一列进行分组\n",
    "group_by_name=df.groupby('name')\n",
    "# print(type(group_by_name))\n",
    "# print(group_by_name)\n",
    "# 查看分组\n",
    "# print(group_by_name.groups)\n",
    "# 分组后的数量\n",
    "# print(group_by_name.count())\n",
    "\n",
    "# 产看分组的情况\n",
    "for name,group in group_by_name:\n",
    "    print(name)# 组的名字\n",
    "    print(group)# 组具体内容\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   name  Year   Salary   Bonus\n",
      "0  BOSS  2016   999999  100000\n",
      "4  BOSS  2017  9999999  200000\n",
      "5  BOSS  2017   999999  300000\n",
      "7  BOSS  2017   999999  400000\n"
     ]
    }
   ],
   "source": [
    "print(group_by_name.get_group('BOSS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "BOSS     4\n",
      "Han      2\n",
      "Lilei    2\n",
      "Name: Year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 按照某一列进行分组, 将name这一列作为分组的键，对year进行分组\n",
    "group_by_name=df['Year'].groupby(df['name'])\n",
    "print(group_by_name.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BOSS', 2016)\n",
      "   name  Year  Salary   Bonus\n",
      "0  BOSS  2016  999999  100000\n",
      "('BOSS', 2017)\n",
      "   name  Year   Salary   Bonus\n",
      "4  BOSS  2017  9999999  200000\n",
      "5  BOSS  2017   999999  300000\n",
      "7  BOSS  2017   999999  400000\n",
      "('Han', 2016)\n",
      "  name  Year  Salary  Bonus\n",
      "3  Han  2016    3000   5000\n",
      "('Han', 2017)\n",
      "  name  Year  Salary  Bonus\n",
      "6  Han  2017    3500   3000\n",
      "('Lilei', 2016)\n",
      "    name  Year  Salary  Bonus\n",
      "1  Lilei  2016   20000  20000\n",
      "2  Lilei  2016   25000  20000\n",
      "   name  Year  Salary   Bonus\n",
      "0  BOSS  2016  999999  100000\n"
     ]
    }
   ],
   "source": [
    "# 按照多列进行分组\n",
    "group_by_name_year=df.groupby(['name','Year'])\n",
    "\n",
    "for name,group in group_by_name_year:\n",
    "    print(name)# 组的名字\n",
    "    print(group)# 组具体内容\n",
    "\n",
    "# 可以选择分组\n",
    "print(group_by_name_year.get_group(('BOSS',2016)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     (40, 65]\n",
      "1     (40, 65]\n",
      "2     (19, 40]\n",
      "3     (19, 40]\n",
      "4     (40, 65]\n",
      "        ...   \n",
      "95    (40, 65]\n",
      "96    (19, 40]\n",
      "97    (40, 65]\n",
      "98    (40, 65]\n",
      "99    (19, 40]\n",
      "Name: Age, Length: 100, dtype: category\n",
      "Categories (3, interval[int64]): [(19, 40] < (40, 65] < (65, 100]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(19, 40]</th>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(40, 65]</th>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(65, 100]</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex         F   M\n",
       "Age              \n",
       "(19, 40]   26  15\n",
       "(40, 65]   30  25\n",
       "(65, 100]   2   2"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将某列数据按数据值分成不同范围段进行分组（groupby）运算\n",
    "df = pd.DataFrame({'Age': np.random.randint(20, 70, 100), \n",
    "                    'Sex': np.random.choice(['M', 'F'], 100), \n",
    "                    })\n",
    "# print(df)\n",
    "#1.划分年龄段 \n",
    "#每一段是什么样子 bins  19-40  40-65   65-100\n",
    "age_groups = pd.cut(df['Age'], bins=[19,40,65,100])\n",
    "print(age_groups)\n",
    "# print(df.groupby(age_groups).count())\n",
    "\n",
    "# # 按‘Age’分组范围和性别（sex）进行制作交叉表\n",
    "pd.crosstab(age_groups, df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Data1  Data2 key1 key2\n",
      "0      5     10    a    x\n",
      "1      5     12    a    y\n",
      "2      0     17    b    y\n",
      "3      0     19    b    x\n",
      "4      0     11    a    y\n"
     ]
    }
   ],
   "source": [
    "df1=pd.DataFrame({'Data1':np.random.randint(0,10,5),\n",
    "                  'Data2':np.random.randint(10,20,5),\n",
    "                  'key1':list('aabba'),\n",
    "                  'key2':list('xyyxy')})\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Data1  Data2\n",
      "key1              \n",
      "a        10     33\n",
      "b         0     36\n"
     ]
    }
   ],
   "source": [
    "print(df1.groupby('key1').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key1\n",
      "a    10\n",
      "b     0\n",
      "Name: Data1, dtype: int32\n",
      "key1\n",
      "a    33\n",
      "b    36\n",
      "Name: Data2, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# 只算data1\n",
    "print(df1['Data1'].groupby(df1['key1']).sum())\n",
    "print(df1.groupby('key1')['Data2'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Data1                     Data2               \n",
      "       sum      mean       std   sum mean       std\n",
      "key1                                               \n",
      "a       10  3.333333  2.886751    33   11  1.000000\n",
      "b        0  0.000000  0.000000    36   18  1.414214\n"
     ]
    }
   ],
   "source": [
    "# 可以同时做多个聚合运算\n",
    "print(df1.groupby('key1').agg(['sum','mean','std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Data1  Data2\n",
      "key1              \n",
      "a         5      2\n",
      "b         0      2\n"
     ]
    }
   ],
   "source": [
    "# 可自定义函数，传入agg方法中 grouped.agg(func)\n",
    "def peak_range(df):\n",
    "    \"\"\"\n",
    "        返回数值范围\n",
    "    \"\"\"\n",
    "    return df.max() - df.min()\n",
    "\n",
    "print(df1.groupby('key1').agg(peak_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
